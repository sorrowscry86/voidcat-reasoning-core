"""
VoidCat Memory Categorization & Search System
=============================================

Intelligent memory categorization and search capabilities with semantic search,
vector embeddings, advanced filtering, and recommendation systems.

This module provides the search foundation for The Scribe's Memory (Pillar II)
of the VoidCat V2 agentic system transformation.

Author: Albedo, Overseer of the Digital Scriptorium
License: MIT
Version: 1.0.0
"""

import json
import math
import re
import time
from collections import Counter, defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple, Union

import nltk
import numpy as np
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize
from nltk.util import ngrams
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

from voidcat_memory_models import (
    BaseMemory,
    ImportanceLevel,
    MemoryCategory,
    MemoryFactory,
    MemoryMetadata,
    MemoryQuery,
    MemoryStatus,
)
from voidcat_memory_storage import MemoryStorageEngine, StorageConfig

# Download required NLTK data
try:
    nltk.download("punkt", quiet=True)
    nltk.download("stopwords", quiet=True)
except:
    print("Warning: NLTK data download failed. Some features may be limited.")


@dataclass
class SearchConfig:
    """Configuration for memory search system."""

    # Semantic search settings
    enable_semantic_search: bool = True
    min_similarity_threshold: float = 0.1
    max_results_per_query: int = 100

    # Vector embedding settings
    tfidf_max_features: int = 5000
    tfidf_ngram_range: Tuple[int, int] = (1, 3)
    tfidf_min_df: int = 2
    tfidf_max_df: float = 0.8

    # Clustering settings
    enable_clustering: bool = True
    cluster_count: int = 20
    cluster_update_interval: int = 3600  # seconds

    # Recommendation settings
    enable_recommendations: bool = True
    recommendation_count: int = 5
    recommendation_decay_factor: float = 0.95

    # Performance settings
    cache_embeddings: bool = True
    embedding_cache_size: int = 1000
    parallel_search_workers: int = 1  # Reduced to 1 to avoid thread pool issues

    # Language processing
    language: str = "english"
    enable_stemming: bool = True
    custom_stopwords: Set[str] = field(default_factory=set)


@dataclass
class SearchResult:
    """Result from memory search with relevance scoring."""

    memory: BaseMemory
    relevance_score: float
    match_type: str  # 'exact', 'semantic', 'fuzzy', 'tag', 'category'
    match_details: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for JSON serialization."""
        return {
            "memory": self.memory.to_dict(),
            "relevance_score": self.relevance_score,
            "match_type": self.match_type,
            "match_details": self.match_details,
        }


@dataclass
class ClusterInfo:
    """Information about a memory cluster."""

    cluster_id: int
    center_keywords: List[str]
    memory_count: int
    avg_importance: float
    dominant_category: MemoryCategory
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for JSON serialization."""
        return {
            "cluster_id": self.cluster_id,
            "center_keywords": self.center_keywords,
            "memory_count": self.memory_count,
            "avg_importance": self.avg_importance,
            "dominant_category": (
                self.dominant_category.value
                if hasattr(self.dominant_category, "value")
                else self.dominant_category
            ),
            "created_at": self.created_at.isoformat(),
        }


class TextProcessor:
    """Advanced text processing for memory content."""

    def __init__(self, config: SearchConfig):
        self.config = config
        self.stemmer = PorterStemmer() if config.enable_stemming else None

        try:
            self.stop_words = set(stopwords.words(config.language))
            self.stop_words.update(config.custom_stopwords)
        except:
            self.stop_words = {
                "the",
                "a",
                "an",
                "and",
                "or",
                "but",
                "in",
                "on",
                "at",
                "to",
                "for",
                "of",
                "with",
                "by",
            }
            self.stop_words.update(config.custom_stopwords)

    def preprocess_text(self, text: str) -> str:
        """Preprocess text for search and analysis."""
        if not text:
            return ""

        # Convert to lowercase
        text = text.lower()

        # Remove special characters but keep spaces
        text = re.sub(r"[^a-zA-Z0-9\s]", " ", text)

        # Remove extra whitespace
        text = " ".join(text.split())

        return text

    def tokenize_and_clean(self, text: str) -> List[str]:
        """Tokenize text and remove stop words."""
        preprocessed = self.preprocess_text(text)

        try:
            tokens = word_tokenize(preprocessed)
        except:
            tokens = preprocessed.split()

        # Remove stop words and short tokens
        cleaned_tokens = [
            token for token in tokens if token not in self.stop_words and len(token) > 2
        ]

        # Apply stemming if enabled
        if self.stemmer:
            cleaned_tokens = [self.stemmer.stem(token) for token in cleaned_tokens]

        return cleaned_tokens

    def extract_keywords(self, text: str, max_keywords: int = 10) -> List[str]:
        """Extract key terms from text."""
        tokens = self.tokenize_and_clean(text)

        # Count frequency
        token_freq = Counter(tokens)

        # Get most common tokens
        keywords = [token for token, freq in token_freq.most_common(max_keywords)]

        return keywords

    def calculate_text_similarity(self, text1: str, text2: str) -> float:
        """Calculate similarity between two texts using simple overlap."""
        tokens1 = set(self.tokenize_and_clean(text1))
        tokens2 = set(self.tokenize_and_clean(text2))

        if not tokens1 or not tokens2:
            return 0.0

        intersection = tokens1.intersection(tokens2)
        union = tokens1.union(tokens2)

        return len(intersection) / len(union) if union else 0.0

    def fuzzy_match(self, query: str, text: str, threshold: float = 0.6) -> bool:
        """Perform fuzzy matching using character-level similarity."""
        query_clean = self.preprocess_text(query)
        text_clean = self.preprocess_text(text)

        if not query_clean or not text_clean:
            return False

        # Simple character-level Jaccard similarity
        query_chars = set(query_clean.replace(" ", ""))
        text_chars = set(text_clean.replace(" ", ""))

        if not query_chars or not text_chars:
            return False

        intersection = query_chars.intersection(text_chars)
        union = query_chars.union(text_chars)

        similarity = len(intersection) / len(union)
        return similarity >= threshold


class VectorEmbeddingEngine:
    """Vector embedding engine for semantic search."""

    def __init__(self, config: SearchConfig):
        self.config = config
        self.text_processor = TextProcessor(config)
        self.vectorizer: Optional[TfidfVectorizer] = None
        self.embeddings: Optional[np.ndarray] = None
        self.memory_ids: List[str] = []
        self.embedding_cache: Dict[str, np.ndarray] = {}
        self.last_update: float = 0

    def _prepare_text_for_vectorization(self, memories: List[BaseMemory]) -> List[str]:
        """Prepare memory content for vectorization."""
        documents = []

        for memory in memories:
            # Combine content, title, and tags
            text_parts = [memory.content]

            if memory.title:
                text_parts.append(memory.title)

            # Add tags if available
            if memory.metadata:
                metadata = MemoryMetadata.from_dict(memory.metadata)
                text_parts.extend(metadata.tags)

            # Add category as context
            category = (
                memory.category.value
                if hasattr(memory.category, "value")
                else memory.category
            )
            text_parts.append(category)

            # Join and preprocess
            combined_text = " ".join(text_parts)
            preprocessed = self.text_processor.preprocess_text(combined_text)
            documents.append(preprocessed)

        return documents

    def build_embeddings(self, memories: List[BaseMemory]) -> bool:
        """Build vector embeddings for all memories."""
        try:
            if not memories:
                return False

            print(f"Building embeddings for {len(memories)} memories...")

            # Prepare documents
            documents = self._prepare_text_for_vectorization(memories)

            # Initialize TF-IDF vectorizer
            self.vectorizer = TfidfVectorizer(
                max_features=self.config.tfidf_max_features,
                ngram_range=self.config.tfidf_ngram_range,
                min_df=self.config.tfidf_min_df,
                max_df=self.config.tfidf_max_df,
                stop_words="english",
            )

            # Fit and transform documents
            self.embeddings = self.vectorizer.fit_transform(documents)
            self.memory_ids = [memory.id for memory in memories]
            self.last_update = time.time()

            print(f"Embeddings built successfully. Shape: {self.embeddings.shape}")
            return True

        except Exception as e:
            print(f"Error building embeddings: {e}")
            return False

    def query_embeddings(
        self, query_text: str, top_k: int = 10
    ) -> List[Tuple[str, float]]:
        """Query embeddings for similar memories."""
        if not self.vectorizer or self.embeddings is None:
            return []

        try:
            # Preprocess query
            preprocessed_query = self.text_processor.preprocess_text(query_text)

            # Transform query to vector space
            query_vector = self.vectorizer.transform([preprocessed_query])

            # Calculate similarity scores
            similarities = cosine_similarity(query_vector, self.embeddings).flatten()

            # Get top-k results above threshold
            results = []
            for i, score in enumerate(similarities):
                if score >= self.config.min_similarity_threshold:
                    results.append((self.memory_ids[i], float(score)))

            # Sort by score and limit results
            results.sort(key=lambda x: x[1], reverse=True)
            return results[:top_k]

        except Exception as e:
            print(f"Error querying embeddings: {e}")
            return []

    def get_similar_memories(
        self, memory_id: str, top_k: int = 5
    ) -> List[Tuple[str, float]]:
        """Find memories similar to a given memory."""
        if not self.embeddings is None and memory_id in self.memory_ids:
            try:
                memory_index = self.memory_ids.index(memory_id)
                memory_vector = self.embeddings[memory_index]

                # Calculate similarities
                similarities = cosine_similarity(
                    [memory_vector], self.embeddings
                ).flatten()

                # Get top-k excluding self
                results = []
                for i, score in enumerate(similarities):
                    if (
                        i != memory_index
                        and score >= self.config.min_similarity_threshold
                    ):
                        results.append((self.memory_ids[i], float(score)))

                results.sort(key=lambda x: x[1], reverse=True)
                return results[:top_k]

            except Exception as e:
                print(f"Error finding similar memories: {e}")

        return []


class MemoryClusteringEngine:
    """Memory clustering engine for organization and discovery."""

    def __init__(self, config: SearchConfig):
        self.config = config
        self.text_processor = TextProcessor(config)
        self.clusters: Dict[int, ClusterInfo] = {}
        self.memory_cluster_map: Dict[str, int] = {}
        self.last_clustering: float = 0

    def cluster_memories(
        self, memories: List[BaseMemory], embeddings: np.ndarray
    ) -> bool:
        """Cluster memories using K-means."""
        try:
            if len(memories) < self.config.cluster_count:
                print(
                    f"Not enough memories ({len(memories)}) for clustering (need {self.config.cluster_count})"
                )
                return False

            print(
                f"Clustering {len(memories)} memories into {self.config.cluster_count} clusters..."
            )

            # Perform K-means clustering
            kmeans = KMeans(
                n_clusters=self.config.cluster_count, random_state=42, n_init=10
            )
            cluster_labels = kmeans.fit_predict(embeddings.toarray())

            # Analyze clusters
            self.clusters = {}
            self.memory_cluster_map = {}

            for i, memory in enumerate(memories):
                cluster_id = cluster_labels[i]
                self.memory_cluster_map[memory.id] = cluster_id

                if cluster_id not in self.clusters:
                    self.clusters[cluster_id] = self._create_cluster_info(
                        cluster_id, []
                    )

            # Update cluster information
            for cluster_id in self.clusters:
                cluster_memories = [
                    memory
                    for i, memory in enumerate(memories)
                    if cluster_labels[i] == cluster_id
                ]
                self.clusters[cluster_id] = self._create_cluster_info(
                    cluster_id, cluster_memories
                )

            self.last_clustering = time.time()
            print(f"Clustering completed. Created {len(self.clusters)} clusters.")
            return True

        except Exception as e:
            print(f"Error clustering memories: {e}")
            return False

    def _create_cluster_info(
        self, cluster_id: int, memories: List[BaseMemory]
    ) -> ClusterInfo:
        """Create cluster information from memories."""
        if not memories:
            return ClusterInfo(
                cluster_id=cluster_id,
                center_keywords=[],
                memory_count=0,
                avg_importance=0.0,
                dominant_category=MemoryCategory.USER_PREFERENCES,
            )

        # Extract keywords from all memories in cluster
        all_text = " ".join(
            [memory.content + " " + (memory.title or "") for memory in memories]
        )
        keywords = self.text_processor.extract_keywords(all_text, max_keywords=5)

        # Calculate average importance
        importance_values = [
            (
                memory.importance.value
                if hasattr(memory.importance, "value")
                else memory.importance
            )
            for memory in memories
        ]
        avg_importance = sum(importance_values) / len(importance_values)

        # Find dominant category
        category_counts = Counter(
            [
                (
                    memory.category.value
                    if hasattr(memory.category, "value")
                    else memory.category
                )
                for memory in memories
            ]
        )
        dominant_category_value = category_counts.most_common(1)[0][0]
        dominant_category = MemoryCategory(dominant_category_value)

        return ClusterInfo(
            cluster_id=cluster_id,
            center_keywords=keywords,
            memory_count=len(memories),
            avg_importance=avg_importance,
            dominant_category=dominant_category,
        )

    def get_cluster_memories(
        self, cluster_id: int, storage_engine: MemoryStorageEngine
    ) -> List[BaseMemory]:
        """Get all memories in a specific cluster."""
        memory_ids = [
            memory_id
            for memory_id, cluster in self.memory_cluster_map.items()
            if cluster == cluster_id
        ]

        memories = []
        for memory_id in memory_ids:
            memory = storage_engine.retrieve_memory(memory_id)
            if memory:
                memories.append(memory)

        return memories

    def recommend_cluster(self, memory: BaseMemory) -> Optional[int]:
        """Recommend a cluster for a new memory."""
        if not self.clusters:
            return None

        best_cluster = None
        best_score = 0.0

        memory_keywords = self.text_processor.extract_keywords(
            memory.content, max_keywords=10
        )
        memory_category = (
            memory.category.value
            if hasattr(memory.category, "value")
            else memory.category
        )

        for cluster_id, cluster_info in self.clusters.items():
            score = 0.0

            # Keyword similarity
            keyword_overlap = len(
                set(memory_keywords).intersection(set(cluster_info.center_keywords))
            )
            score += keyword_overlap * 0.5

            # Category match
            cluster_category = (
                cluster_info.dominant_category.value
                if hasattr(cluster_info.dominant_category, "value")
                else cluster_info.dominant_category
            )
            if memory_category == cluster_category:
                score += 2.0

            # Importance similarity
            memory_importance = (
                memory.importance.value
                if hasattr(memory.importance, "value")
                else memory.importance
            )
            importance_diff = abs(memory_importance - cluster_info.avg_importance)
            score += max(0, 1.0 - importance_diff / 10.0)

            if score > best_score:
                best_score = score
                best_cluster = cluster_id

        return best_cluster


class MemorySearchEngine:
    """
    Comprehensive memory search engine with semantic search, categorization,
    filtering, clustering, and recommendation capabilities.
    """

    def __init__(
        self, storage_engine: MemoryStorageEngine, config: Optional[SearchConfig] = None
    ):
        self.storage_engine = storage_engine
        self.config = config or SearchConfig()
        self.text_processor = TextProcessor(self.config)

        # Initialize components
        self.embedding_engine = (
            VectorEmbeddingEngine(self.config)
            if self.config.enable_semantic_search
            else None
        )
        self.clustering_engine = (
            MemoryClusteringEngine(self.config)
            if self.config.enable_clustering
            else None
        )

        # Search statistics
        self.search_stats = {
            "total_searches": 0,
            "semantic_searches": 0,
            "category_searches": 0,
            "tag_searches": 0,
            "fuzzy_searches": 0,
            "avg_response_time": 0.0,
        }

        # Initialize embeddings
        self._initialize_embeddings()

    def _initialize_embeddings(self):
        """Initialize embeddings from existing memories."""
        if not self.embedding_engine:
            return

        try:
            # Get all active memories
            query = MemoryQuery(
                status=MemoryStatus.ACTIVE,
                limit=10000,  # Large limit to get all memories
            )
            memories = self.storage_engine.search_memories(query)

            if memories:
                success = self.embedding_engine.build_embeddings(memories)
                if success and self.clustering_engine:
                    self.clustering_engine.cluster_memories(
                        memories, self.embedding_engine.embeddings
                    )

        except Exception as e:
            print(f"Warning: Failed to initialize embeddings: {e}")

    def search(self, query: MemoryQuery) -> List[SearchResult]:
        """
        Comprehensive memory search with multiple strategies.
        """
        start_time = time.time()
        results = []

        try:
            self.search_stats["total_searches"] += 1

            # Strategy 1: Basic storage engine search (category, tags, importance filters)
            base_memories = self.storage_engine.search_memories(query)

            if not query.text:
                # No text query - return filtered results
                for memory in base_memories:
                    results.append(
                        SearchResult(
                            memory=memory,
                            relevance_score=1.0,
                            match_type="category" if query.categories else "filter",
                        )
                    )
            else:
                # Strategy 2: Semantic search if enabled
                if self.embedding_engine and self.config.enable_semantic_search:
                    semantic_results = self._semantic_search(query.text, base_memories)
                    results.extend(semantic_results)
                    self.search_stats["semantic_searches"] += 1

                # Strategy 3: Exact text matching
                exact_results = self._exact_text_search(query.text, base_memories)
                results.extend(exact_results)

                # Strategy 4: Fuzzy matching
                fuzzy_results = self._fuzzy_search(query.text, base_memories)
                results.extend(fuzzy_results)
                self.search_stats["fuzzy_searches"] += 1

            # Deduplicate and sort results
            results = self._deduplicate_results(results)
            results = self._rank_results(results, query)

            # Apply pagination
            start_idx = query.offset
            end_idx = start_idx + query.limit
            results = results[start_idx:end_idx]

            # Update statistics
            response_time = time.time() - start_time
            self._update_response_time_stats(response_time)

            return results

        except Exception as e:
            print(f"Error in memory search: {e}")
            return []

    def _semantic_search(
        self, query_text: str, candidate_memories: List[BaseMemory]
    ) -> List[SearchResult]:
        """Perform semantic search using vector embeddings."""
        results = []

        if not self.embedding_engine or not self.embedding_engine.embeddings:
            return results

        try:
            # Get semantic similarity results
            semantic_matches = self.embedding_engine.query_embeddings(
                query_text, top_k=min(50, len(candidate_memories))
            )

            # Convert to SearchResults
            candidate_id_set = {memory.id for memory in candidate_memories}

            for memory_id, similarity_score in semantic_matches:
                if memory_id in candidate_id_set:
                    memory = next(
                        (m for m in candidate_memories if m.id == memory_id), None
                    )
                    if memory:
                        results.append(
                            SearchResult(
                                memory=memory,
                                relevance_score=similarity_score,
                                match_type="semantic",
                                match_details={"similarity_score": similarity_score},
                            )
                        )

        except Exception as e:
            print(f"Error in semantic search: {e}")

        return results

    def _exact_text_search(
        self, query_text: str, candidate_memories: List[BaseMemory]
    ) -> List[SearchResult]:
        """Perform exact text matching search."""
        results = []
        query_lower = query_text.lower()

        for memory in candidate_memories:
            content_lower = memory.content.lower()
            title_lower = (memory.title or "").lower()

            # Check for exact matches
            content_match = query_lower in content_lower
            title_match = query_lower in title_lower

            if content_match or title_match:
                # Calculate relevance based on match position and frequency
                relevance = 0.0

                if title_match:
                    relevance += 0.8  # Title matches are more important

                if content_match:
                    match_count = content_lower.count(query_lower)
                    relevance += min(0.6, match_count * 0.1)

                results.append(
                    SearchResult(
                        memory=memory,
                        relevance_score=relevance,
                        match_type="exact",
                        match_details={
                            "title_match": title_match,
                            "content_match": content_match,
                        },
                    )
                )

        return results

    def _fuzzy_search(
        self, query_text: str, candidate_memories: List[BaseMemory]
    ) -> List[SearchResult]:
        """Perform fuzzy text matching search."""
        results = []

        for memory in candidate_memories:
            # Check content
            content_fuzzy = self.text_processor.fuzzy_match(query_text, memory.content)
            title_fuzzy = self.text_processor.fuzzy_match(
                query_text, memory.title or ""
            )

            if content_fuzzy or title_fuzzy:
                # Calculate fuzzy relevance
                relevance = 0.0

                if title_fuzzy:
                    relevance += 0.4

                if content_fuzzy:
                    relevance += 0.3

                results.append(
                    SearchResult(
                        memory=memory,
                        relevance_score=relevance,
                        match_type="fuzzy",
                        match_details={
                            "title_fuzzy": title_fuzzy,
                            "content_fuzzy": content_fuzzy,
                        },
                    )
                )

        return results

    def _deduplicate_results(self, results: List[SearchResult]) -> List[SearchResult]:
        """Remove duplicate memories, keeping the highest scoring result."""
        memory_scores = {}

        for result in results:
            memory_id = result.memory.id
            if (
                memory_id not in memory_scores
                or result.relevance_score > memory_scores[memory_id].relevance_score
            ):
                memory_scores[memory_id] = result

        return list(memory_scores.values())

    def _rank_results(
        self, results: List[SearchResult], query: MemoryQuery
    ) -> List[SearchResult]:
        """Rank and sort search results."""
        for result in results:
            # Apply importance weighting
            importance_value = (
                result.memory.importance.value
                if hasattr(result.memory.importance, "value")
                else result.memory.importance
            )
            importance_weight = importance_value / 10.0
            result.relevance_score *= 1.0 + importance_weight * 0.5

            # Apply recency weighting
            if result.memory.metadata:
                metadata = MemoryMetadata.from_dict(result.memory.metadata)
                days_since_access = (
                    datetime.now(timezone.utc) - metadata.last_accessed
                ).days
                recency_weight = max(0.5, 1.0 - (days_since_access * 0.01))
                result.relevance_score *= recency_weight

            # Apply access frequency weighting
            if result.memory.metadata:
                metadata = MemoryMetadata.from_dict(result.memory.metadata)
                access_weight = min(
                    2.0, 1.0 + math.log(metadata.access_count + 1) * 0.1
                )
                result.relevance_score *= access_weight

        # Sort by relevance score
        results.sort(key=lambda x: x.relevance_score, reverse=True)
        return results

    def find_similar_memories(
        self, memory_id: str, max_results: int = 5
    ) -> List[SearchResult]:
        """Find memories similar to a given memory."""
        results = []

        # Get the source memory
        source_memory = self.storage_engine.retrieve_memory(memory_id)
        if not source_memory:
            return results

        try:
            # Use embedding-based similarity if available
            if self.embedding_engine:
                similar_pairs = self.embedding_engine.get_similar_memories(
                    memory_id, max_results
                )

                for similar_id, similarity_score in similar_pairs:
                    similar_memory = self.storage_engine.retrieve_memory(similar_id)
                    if similar_memory:
                        results.append(
                            SearchResult(
                                memory=similar_memory,
                                relevance_score=similarity_score,
                                match_type="similarity",
                                match_details={"similarity_score": similarity_score},
                            )
                        )

            # Fallback to category and tag similarity
            if not results:
                query = MemoryQuery(
                    categories=[source_memory.category], limit=max_results * 2
                )

                candidate_memories = self.storage_engine.search_memories(query)

                for memory in candidate_memories:
                    if memory.id != memory_id:
                        # Calculate similarity based on tags and content
                        similarity = self._calculate_memory_similarity(
                            source_memory, memory
                        )
                        if similarity > 0.1:
                            results.append(
                                SearchResult(
                                    memory=memory,
                                    relevance_score=similarity,
                                    match_type="category_similarity",
                                    match_details={"similarity_score": similarity},
                                )
                            )

                results.sort(key=lambda x: x.relevance_score, reverse=True)
                results = results[:max_results]

        except Exception as e:
            print(f"Error finding similar memories: {e}")

        return results

    def _calculate_memory_similarity(
        self, memory1: BaseMemory, memory2: BaseMemory
    ) -> float:
        """Calculate similarity between two memories."""
        similarity = 0.0

        # Category similarity
        if memory1.category == memory2.category:
            similarity += 0.3

        # Tag similarity
        if memory1.metadata and memory2.metadata:
            metadata1 = MemoryMetadata.from_dict(memory1.metadata)
            metadata2 = MemoryMetadata.from_dict(memory2.metadata)

            tag_intersection = metadata1.tags.intersection(metadata2.tags)
            tag_union = metadata1.tags.union(metadata2.tags)

            if tag_union:
                tag_similarity = len(tag_intersection) / len(tag_union)
                similarity += tag_similarity * 0.4

        # Content similarity
        content_similarity = self.text_processor.calculate_text_similarity(
            memory1.content, memory2.content
        )
        similarity += content_similarity * 0.3

        return similarity

    def get_memory_recommendations(
        self, memory_id: str, max_recommendations: int = 5
    ) -> List[SearchResult]:
        """Get memory recommendations based on a memory."""
        if not self.config.enable_recommendations:
            return []

        # Find similar memories
        similar_memories = self.find_similar_memories(
            memory_id, max_recommendations * 2
        )

        # Apply recommendation scoring
        recommendations = []
        for result in similar_memories:
            # Adjust score for recommendation context
            recommendation_score = (
                result.relevance_score * self.config.recommendation_decay_factor
            )

            recommendations.append(
                SearchResult(
                    memory=result.memory,
                    relevance_score=recommendation_score,
                    match_type="recommendation",
                    match_details={
                        "original_score": result.relevance_score,
                        "source_memory_id": memory_id,
                    },
                )
            )

        return recommendations[:max_recommendations]

    def get_cluster_overview(self) -> Dict[str, Any]:
        """Get overview of memory clusters."""
        if not self.clustering_engine or not self.clustering_engine.clusters:
            return {}

        cluster_overview = {}
        for cluster_id, cluster_info in self.clustering_engine.clusters.items():
            cluster_overview[f"cluster_{cluster_id}"] = cluster_info.to_dict()

        return {
            "total_clusters": len(self.clustering_engine.clusters),
            "clusters": cluster_overview,
            "last_clustering": self.clustering_engine.last_clustering,
        }

    def _update_response_time_stats(self, response_time: float):
        """Update response time statistics."""
        current_avg = self.search_stats["avg_response_time"]
        total_searches = self.search_stats["total_searches"]

        # Calculate new average
        new_avg = (
            (current_avg * (total_searches - 1)) + response_time
        ) / total_searches
        self.search_stats["avg_response_time"] = new_avg

    def get_search_statistics(self) -> Dict[str, Any]:
        """Get search engine statistics."""
        return {
            **self.search_stats,
            "embedding_status": {
                "enabled": self.embedding_engine is not None,
                "embeddings_built": (
                    self.embedding_engine.embeddings is not None
                    if self.embedding_engine
                    else False
                ),
                "memory_count": (
                    len(self.embedding_engine.memory_ids)
                    if self.embedding_engine
                    else 0
                ),
                "last_update": (
                    self.embedding_engine.last_update if self.embedding_engine else 0
                ),
            },
            "clustering_status": {
                "enabled": self.clustering_engine is not None,
                "cluster_count": (
                    len(self.clustering_engine.clusters)
                    if self.clustering_engine
                    else 0
                ),
                "last_clustering": (
                    self.clustering_engine.last_clustering
                    if self.clustering_engine
                    else 0
                ),
            },
        }

    def refresh_embeddings(self) -> bool:
        """Refresh embeddings with current memory state."""
        if not self.embedding_engine:
            return False

        print("Refreshing memory embeddings...")
        self._initialize_embeddings()
        return True


# Performance testing and validation
if __name__ == "__main__":
    import tempfile
    from pathlib import Path

    print("VoidCat Memory Search Engine - Performance Test Suite")
    print("=" * 60)

    # Create temporary directory for testing
    with tempfile.TemporaryDirectory() as temp_dir:
        # Initialize storage and search engines
        storage_config = StorageConfig(
            base_dir=Path(temp_dir) / "memory_storage",
            backup_dir=Path(temp_dir) / "memory_backups",
            index_dir=Path(temp_dir) / "memory_indexes",
        )

        search_config = SearchConfig(
            enable_semantic_search=True,
            enable_clustering=True,
            enable_recommendations=True,
        )

        storage_engine = MemoryStorageEngine(storage_config)
        search_engine = MemorySearchEngine(storage_engine, search_config)

        # Test 1: Create test memories
        print(f"\nüìù Test 1: Creating test memories...")
        test_memories = []

        # Create diverse memories for testing
        memory_data = [
            (
                "User prefers dark mode",
                "user_interface_preference",
                MemoryCategory.USER_PREFERENCES,
            ),
            (
                "Python programming language",
                "programming_knowledge",
                MemoryCategory.LEARNED_HEURISTICS,
            ),
            (
                "Meeting with client tomorrow",
                "schedule_information",
                MemoryCategory.CONVERSATION_HISTORY,
            ),
            (
                "Database optimization techniques",
                "technical_knowledge",
                MemoryCategory.LEARNED_HEURISTICS,
            ),
            (
                "User likes detailed explanations",
                "communication_preference",
                MemoryCategory.USER_PREFERENCES,
            ),
        ]

        for content, key, category in memory_data:
            if category == MemoryCategory.USER_PREFERENCES:
                memory = MemoryFactory.create_user_preference(
                    key=key, value=content, importance=ImportanceLevel.MEDIUM
                )
            else:
                memory = BaseMemory(
                    category=category,
                    content=content,
                    title=f"{key.replace('_', ' ').title()}",
                    importance=ImportanceLevel.MEDIUM,
                )
            memory.add_tag("test")
            memory.add_tag(key.split("_")[0])

            success = storage_engine.store_memory(memory)
            if success:
                test_memories.append(memory)

        print(f"‚úÖ Created {len(test_memories)} test memories")

        # Test 2: Basic search
        print(f"\nüîç Test 2: Basic search functionality...")
        start_time = time.time()

        query = MemoryQuery(text="user preferences", limit=10)

        results = search_engine.search(query)
        search_time = time.time() - start_time

        print(f"‚úÖ Found {len(results)} results in {search_time*1000:.1f}ms")
        for result in results[:3]:
            print(
                f"  - {result.memory.title}: {result.relevance_score:.3f} ({result.match_type})"
            )

        # Test 3: Category filtering
        print(f"\nüìÇ Test 3: Category filtering...")
        category_query = MemoryQuery(
            categories=[MemoryCategory.USER_PREFERENCES], limit=10
        )

        category_results = search_engine.search(category_query)
        print(f"‚úÖ Found {len(category_results)} user preference memories")

        # Test 4: Similar memory finding
        print(f"\nüîó Test 4: Similar memory finding...")
        if test_memories:
            similar_results = search_engine.find_similar_memories(
                test_memories[0].id, max_results=3
            )
            print(f"‚úÖ Found {len(similar_results)} similar memories")
            for result in similar_results:
                print(f"  - {result.memory.title}: {result.relevance_score:.3f}")

        # Test 5: Memory recommendations
        print(f"\nüí° Test 5: Memory recommendations...")
        if test_memories:
            recommendations = search_engine.get_memory_recommendations(
                test_memories[0].id, max_recommendations=3
            )
            print(f"‚úÖ Generated {len(recommendations)} recommendations")

        # Test 6: Search statistics
        print(f"\nüìä Test 6: Search statistics...")
        stats = search_engine.get_search_statistics()
        print(f"Total searches: {stats['total_searches']}")
        print(f"Average response time: {stats['avg_response_time']*1000:.1f}ms")
        print(f"Embeddings enabled: {stats['embedding_status']['enabled']}")
        print(f"Clustering enabled: {stats['clustering_status']['enabled']}")

        # Performance summary
        print(f"\nüéØ PERFORMANCE SUMMARY:")
        print(f"‚úÖ Search response time: {search_time*1000:.1f}ms")
        print(f"‚úÖ Memory creation: {len(test_memories)} memories")
        print(f"‚úÖ Search functionality: Working")
        print(f"‚úÖ Similar memory finding: Working")
        print(f"‚úÖ Recommendations: Working")

        # Close engines
        storage_engine.close()

        print("\n[SUCCESS] All search tests completed! üöÄ")
